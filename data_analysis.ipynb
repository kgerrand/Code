{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special Topics in Artificial Intelligence and Deep Learning (SCIFM0002)\n",
    "\n",
    "### **Programming Project 2 - Dunking Biscuits in Tea**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>phi</th>\n",
       "      <th>eta</th>\n",
       "      <th>L</th>\n",
       "      <th>t</th>\n",
       "      <th>biscuit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.073897</td>\n",
       "      <td>1.333006</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.011196</td>\n",
       "      <td>19.362214</td>\n",
       "      <td>Digestive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.080946</td>\n",
       "      <td>1.476758</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>0.005894</td>\n",
       "      <td>11.852589</td>\n",
       "      <td>Digestive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.087408</td>\n",
       "      <td>1.477141</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>0.009249</td>\n",
       "      <td>24.793669</td>\n",
       "      <td>Digestive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.070793</td>\n",
       "      <td>1.502001</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>16.292780</td>\n",
       "      <td>Hobnob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.058917</td>\n",
       "      <td>1.548274</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>0.002291</td>\n",
       "      <td>13.662271</td>\n",
       "      <td>Hobnob</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gamma       phi       eta         L          t    biscuit\n",
       "0  0.073897  1.333006  0.000999  0.011196  19.362214  Digestive\n",
       "1  0.080946  1.476758  0.001012  0.005894  11.852589  Digestive\n",
       "2  0.087408  1.477141  0.000984  0.009249  24.793669  Digestive\n",
       "3  0.070793  1.502001  0.001002  0.003774  16.292780     Hobnob\n",
       "4  0.058917  1.548274  0.001004  0.002291  13.662271     Hobnob"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dunking_df = pd.read_csv('data/dunking-data.csv')\n",
    "dunking_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>L</th>\n",
       "      <th>dL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.008087</td>\n",
       "      <td>0.000392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.727273</td>\n",
       "      <td>0.008253</td>\n",
       "      <td>0.000270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.454545</td>\n",
       "      <td>0.008607</td>\n",
       "      <td>0.000501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.181818</td>\n",
       "      <td>0.008920</td>\n",
       "      <td>0.000267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.909091</td>\n",
       "      <td>0.009604</td>\n",
       "      <td>0.000274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           t         L        dL\n",
       "0  30.000000  0.008087  0.000392\n",
       "1  32.727273  0.008253  0.000270\n",
       "2  35.454545  0.008607  0.000501\n",
       "3  38.181818  0.008920  0.000267\n",
       "4  40.909091  0.009604  0.000274"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr1 = pd.read_csv('data/tr-1.csv')\n",
    "tr2 = pd.read_csv('data/tr-2.csv')\n",
    "tr3 = pd.read_csv('data/tr-3.csv')\n",
    "\n",
    "tr1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>phi</th>\n",
       "      <th>eta</th>\n",
       "      <th>L</th>\n",
       "      <th>t</th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.084596</td>\n",
       "      <td>1.557367</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.003221</td>\n",
       "      <td>24.231107</td>\n",
       "      <td>7.453712e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064291</td>\n",
       "      <td>1.538842</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>22.169765</td>\n",
       "      <td>2.600680e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.086224</td>\n",
       "      <td>1.546138</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.003036</td>\n",
       "      <td>23.257709</td>\n",
       "      <td>3.734618e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.082859</td>\n",
       "      <td>1.566878</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>12.717432</td>\n",
       "      <td>7.567173e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.090832</td>\n",
       "      <td>1.570229</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>15.189146</td>\n",
       "      <td>8.239067e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gamma       phi       eta         L          t             r\n",
       "0  0.084596  1.557367  0.000981  0.003221  24.231107  7.453712e-07\n",
       "1  0.064291  1.538842  0.000998  0.002395  22.169765  2.600680e-07\n",
       "2  0.086224  1.546138  0.001008  0.003036  23.257709  3.734618e-07\n",
       "3  0.082859  1.566878  0.000997  0.001261  12.717432  7.567173e-07\n",
       "4  0.090832  1.570229  0.001002  0.000576  15.189146  8.239067e-07"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "microscopy_df = pd.read_csv('data/microscopy-data.csv')\n",
    "\n",
    "microscopy_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Using a Machine Learning Algorithm to Identify Biscuit Type*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring & Optimising Classification Model Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up data for machine learning models\n",
    "\n",
    "# identifying features and target variable (biscuit type)\n",
    "X = dunking_df.drop('biscuit', axis=1)\n",
    "y = dunking_df['biscuit']\n",
    "\n",
    "# splitting into training and testing data - 70% training, 30% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# splitting testing data further into testing and validation data - 18% testing, 12% validation\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.4, random_state=42)\n",
    "\n",
    "\n",
    "# checking categories are balanced (within 5% of each other)\n",
    "digestive_num = y_train.value_counts()['Digestive']\n",
    "rich_tea_num = y_train.value_counts()['Rich Tea']\n",
    "hobnob_num = y_train.value_counts()['Hobnob']\n",
    "\n",
    "assert abs(digestive_num - rich_tea_num) < 0.05*digestive_num\n",
    "assert abs(digestive_num - hobnob_num) < 0.05*digestive_num\n",
    "assert abs(rich_tea_num - hobnob_num) < 0.05*rich_tea_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a RF classifier\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# fitting model to test data\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall F1: 0.785\n",
      "Average Cross-validation F1 score: 0.818\n"
     ]
    }
   ],
   "source": [
    "# evaluating model using F1 score and cross-validation\n",
    "overall_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f'Overall F1: {overall_f1:.3f}')\n",
    "\n",
    "cv_scores = cross_val_score(rf, X, y, cv=5, scoring='f1_weighted')\n",
    "print(f'Average Cross-validation F1 score: {np.mean(cv_scores):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Gradient-Boosted Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a GBT classifier\n",
    "gbt = GradientBoostingClassifier(n_estimators=200, random_state=42)\n",
    "\n",
    "gbt.fit(X_train, y_train)\n",
    "\n",
    "# fitting model to test data\n",
    "y_pred = gbt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall F1: 0.817\n",
      "Average Cross-validation F1 score: 0.826\n"
     ]
    }
   ],
   "source": [
    "# evaluating model using F1 score and cross-validation\n",
    "overall_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f'Overall F1: {overall_f1:.3f}')\n",
    "\n",
    "cv_scores = cross_val_score(gbt, X, y, cv=5, scoring='f1_weighted')\n",
    "print(f'Average Cross-validation F1 score: {np.mean(cv_scores):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a NN MLP classifier\n",
    "nn = MLPClassifier(random_state=42)\n",
    "\n",
    "nn.fit(X_train, y_train)\n",
    "\n",
    "# fitting model to test data\n",
    "y_pred = nn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall F1: 0.267\n",
      "Average Cross-validation F1 score: 0.218\n"
     ]
    }
   ],
   "source": [
    "# evaluating model using F1 score and cross-validation\n",
    "overall_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f'Overall F1: {overall_f1:.3f}')\n",
    "\n",
    "cv_scores = cross_val_score(nn, X, y, cv=5, scoring='f1_weighted')\n",
    "print(f'Average Cross-validation F1 score: {np.mean(cv_scores):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial testing shows that the neural network is not appropriate for these data, likely as it is a relatively small and straightforward dataset. The random forest and gradient-boosted tree both perform well, but the gradient-boosted tree achieves the best F1 and cross-validation scores at this point. Therefore, the gradient-boosted tree is the choice of algorithm going forward, and will be optimised further through exploration of hyperparameter combinations in a grid search. This is done using the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Optimation of Gradient-Boosted Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining hyperparamters to search through\n",
    "param_grid = {'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'criterion': ['friedman_mse', 'squared_error'],\n",
    "    'random_state': [42],\n",
    "    'learning_rate': [0.01, 0.1, 0.001],}\n",
    "\n",
    "# Initialize the grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(gbt, param_grid, n_jobs=-1, cv=5, scoring='f1')\n",
    "\n",
    "# Perform the grid search on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# extracting best parameters and score\n",
    "results = grid_search.best_estimator_\n",
    "\n",
    "validation_f1 = results.score(X_val, y_val)\n",
    "\n",
    "print(f'Validation F1 Score: {validation_f1:.3f}')\n",
    "print(f'Best Parameters: {grid_search.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigating Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Individual Class Performance of Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating classifier using F1 score - obtaining values for each biscuit type\n",
    "f1 = f1_score(y_test, y_pred, average=None, labels=['Digestive', 'Hobnob', 'Rich Tea'])\n",
    "print(f'F1: {[f\"{score:.3f}\" for score in f1]}')\n",
    "\n",
    "# printing confusion matrix\n",
    "confusion_matrix = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating percentage drop in F1 score between biscuit types\n",
    "f1_diff = abs(f1[0] - f1[1])\n",
    "f1_drop = f1_diff/f1[0] * 100\n",
    "print(f'Percentage drop in F1 score from Digestive to Hobnob: {f1_drop:.2f}%')\n",
    "\n",
    "f1_diff = abs(f1[1] - f1[2])\n",
    "f1_drop = f1_diff/f1[1] * 100\n",
    "print(f'Percentage drop in F1 score from Rich Tea to Hobnob: {f1_drop:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values show that the model is able to accurately categorise data into biscuit type over 80% of the time. However, there is a significant drop in performance when considering the Hobnob data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identifying what hobnobs are being most commonly misclassified as\n",
    "hobnob_matrix = confusion_matrix.loc['Hobnob']\n",
    "hobnob_matrix = hobnob_matrix.drop('Hobnob')\n",
    "max_value = hobnob_matrix.max()\n",
    "hobnob_matrix = (hobnob_matrix / hobnob_matrix.sum())*100\n",
    "\n",
    "print(f'Hobnobs are most commonly misclassified as: {hobnob_matrix.idxmax()}. {hobnob_matrix.max():.1f}% (n={max_value}) of Hobnob false positives are this biscuit type.')\n",
    "\n",
    "# exploring to see if this is reciprocated\n",
    "rich_tea_matrix = confusion_matrix.loc['Rich Tea']\n",
    "rich_tea_matrix = rich_tea_matrix.drop('Rich Tea')\n",
    "max_value = rich_tea_matrix.max()\n",
    "rich_tea_matrix = (rich_tea_matrix / rich_tea_matrix.sum())*100\n",
    "\n",
    "\n",
    "print(f'Rich Teas are most commonly misclassified as: {rich_tea_matrix.idxmax()}. {rich_tea_matrix.max():.1f}% (n={max_value}) of Rich Tea false positives are this biscuit type.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results show that while the algorithm shows significant potential for classification of biscuit type because of its high F1 and cross-validation scores, it struggles most with distinguishing hobnobs and rich teas. This is likely because their distributions are most similar and digestive is distinguishable from both, as shown in the boxplot of *L* in the above exploratory data analysis.\n",
    "\n",
    "This is worth considering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Exploring Pore Radius Using Microscopy Dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>phi</th>\n",
       "      <th>eta</th>\n",
       "      <th>L</th>\n",
       "      <th>t</th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.084596</td>\n",
       "      <td>1.557367</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.003221</td>\n",
       "      <td>24.231107</td>\n",
       "      <td>7.453712e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064291</td>\n",
       "      <td>1.538842</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>22.169765</td>\n",
       "      <td>2.600680e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.086224</td>\n",
       "      <td>1.546138</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.003036</td>\n",
       "      <td>23.257709</td>\n",
       "      <td>3.734618e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.082859</td>\n",
       "      <td>1.566878</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>12.717432</td>\n",
       "      <td>7.567173e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.090832</td>\n",
       "      <td>1.570229</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>15.189146</td>\n",
       "      <td>8.239067e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gamma       phi       eta         L          t             r\n",
       "0  0.084596  1.557367  0.000981  0.003221  24.231107  7.453712e-07\n",
       "1  0.064291  1.538842  0.000998  0.002395  22.169765  2.600680e-07\n",
       "2  0.086224  1.546138  0.001008  0.003036  23.257709  3.734618e-07\n",
       "3  0.082859  1.566878  0.000997  0.001261  12.717432  7.567173e-07\n",
       "4  0.090832  1.570229  0.001002  0.000576  15.189146  8.239067e-07"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "microscopy_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Calculating a Capillary Flow Rate Coefficient for the Different Biscuit Types*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr1['gamma'] = 6.78e-2\n",
    "tr1['eta'] = 9.93e-4\n",
    "tr1['phi'] = 1.45\n",
    "\n",
    "# calculating r based on Washburn equation\n",
    "tr1['r'] = (tr1['L']**2 * 2*tr1['eta'])/(tr1['gamma']*tr1['t']*np.cos(tr1['phi']))\n",
    "\n",
    "average_r = tr1['r'].mean()\n",
    "print(f'Average r for tr-1: {average_r} m')\n",
    "# hobnob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr2['gamma'] = 6.78e-2\n",
    "tr2['eta'] = 9.93e-4\n",
    "tr2['phi'] = 1.45\n",
    "\n",
    "# calculating r based on Washburn equation\n",
    "tr2['r'] = (tr2['L']**2 * 2*tr2['eta'])/(tr2['gamma']*tr2['t']*np.cos(tr2['phi']))\n",
    "\n",
    "average_r = tr2['r'].mean()\n",
    "print(f'Average r for tr-2: {average_r} m')\n",
    "# rich tea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr3['gamma'] = 6.78e-2\n",
    "tr3['eta'] = 9.93e-4\n",
    "tr3['phi'] = 1.45\n",
    "\n",
    "# calculating r based on Washburn equation\n",
    "tr3['r'] = (tr3['L']**2 * 2*tr3['eta'])/(tr3['gamma']*tr3['t']*np.cos(tr3['phi']))\n",
    "\n",
    "average_r = tr3['r'].mean()\n",
    "print(f'Average r for tr-3: {average_r} m')\n",
    "# digestive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot showing r for each tr\n",
    "tr1['tr'] = 'tr-1'\n",
    "tr2['tr'] = 'tr-2'\n",
    "tr3['tr'] = 'tr-3'\n",
    "\n",
    "tr = pd.concat([tr1, tr2, tr3])\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.boxplot(x='tr', y='r', data=tr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Assessing the Washburn Equation*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Using a Machine Learning Regressor to Compete with the Washburn Equation*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
